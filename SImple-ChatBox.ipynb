{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7544b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as js\n",
    "import re\n",
    "\n",
    "with open('E:/Ai project/.ipynb_checkpoints/instents.json', 'r') as f:\n",
    "    data = js.load(f)['intents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b870e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mahan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mahan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca755ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(word):\n",
    "    \n",
    "    word = re.sub(\"[^a-z0-9]*\", \"\", word.lower())\n",
    "    word = lemmatizer.lemmatize(word)\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "896a2497",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = []\n",
    "token2idx = {'<PAD>' : 0, '<UNK>' : 1}\n",
    "counter = 2\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for item in data:\n",
    "    label = item['tag'].lower()\n",
    "    \n",
    "    for pattern in item['patterns']:\n",
    "        sentence = ''\n",
    "        \n",
    "        for word in pattern.split():\n",
    "            clean_word = clean_words(word)\n",
    "            sentence += word + ''\n",
    "            \n",
    "            if clean_word not in token2idx.keys():\n",
    "                token2idx[clean_word] = counter\n",
    "                counter += 1\n",
    "                \n",
    "        raw_dataset.append(tuple([sentence.strip(), label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00705197",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(sent) for item in data for sent in item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e40944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sent(sent, max_len, token2isx, PAD = 0, UNK = 1):\n",
    "    \n",
    "    token_list = []\n",
    "    \n",
    "    for token in sent.split():\n",
    "        token = token2idx.get(clean_words(token), UNK)\n",
    "        token_list.append(token)\n",
    "        \n",
    "    if len(token_list) < max_len:\n",
    "        diff = max_len - len(token_list)\n",
    "        token_list.extend([PAD] * diff)\n",
    "    elif len(token_list) > max_len:\n",
    "        token_list = token_list[:max_len]\n",
    "        \n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53703b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2label = {item['tag'].lower(): idx for idx, item in enumerate(data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4935e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2tag = {v : k for k, v in tag2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55ab45db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for sentence, tag in raw_dataset:\n",
    "    token_list = tokenize_sent(sentence, max_len, token2idx)\n",
    "    label = tag2label[tag]\n",
    "    dataset.append(tuple([token_list, label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bb7a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = 16, shuffle = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30c84df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classification, self).__init__()\n",
    "        self.embedd = torch.nn.Embedding(len(token2idx.keys()), 16, padding_idx = 0)\n",
    "        self.fc1 = torch.nn.Linear(16, 32)\n",
    "        self.fc2 = torch.nn.Linear(32, len(tag2label.keys()))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedd(x)\n",
    "        x = torch.sum(x, dim = 0)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.log_softmax(self.fc2(x), dim = 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec03cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classification()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9aea7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [5 / 100], Step[1 / 1], Loss: 0.4536Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [10 / 100], Step[1 / 1], Loss: 0.3653Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [15 / 100], Step[1 / 1], Loss: 0.3514Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [20 / 100], Step[1 / 1], Loss: 0.3495Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [25 / 100], Step[1 / 1], Loss: 0.3491Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [30 / 100], Step[1 / 1], Loss: 0.3491Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [35 / 100], Step[1 / 1], Loss: 0.3491Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [40 / 100], Step[1 / 1], Loss: 0.349Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [45 / 100], Step[1 / 1], Loss: 0.349Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [50 / 100], Step[1 / 1], Loss: 0.349Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [55 / 100], Step[1 / 1], Loss: 0.349Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [60 / 100], Step[1 / 1], Loss: 0.349Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [65 / 100], Step[1 / 1], Loss: 0.349Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [70 / 100], Step[1 / 1], Loss: 0.349Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [75 / 100], Step[1 / 1], Loss: 0.349Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [80 / 100], Step[1 / 1], Loss: 0.349Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [85 / 100], Step[1 / 1], Loss: 0.349Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [90 / 100], Step[1 / 1], Loss: 0.349Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [95 / 100], Step[1 / 1], Loss: 0.349Accuracy : 83.33333587646484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch [100 / 100], Step[1 / 1], Loss: 0.349Accuracy : 83.33333587646484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracies, losses = [], []\n",
    "\n",
    "total_step = len(dataloader)\n",
    "\n",
    "for epoch in range(100):\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    for i ,(features, labels) in enumerate(dataloader):\n",
    "        fetures = torch.stack(features, dim = 0)\n",
    "        \n",
    "        output = model(fetures)\n",
    "        \n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        correct += (torch.argmax(output, dim = 1) == labels).float().sum()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "    accuracy = (100 * correct) / total\n",
    "    accuracies.append(accuracy)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    if (epoch +1) % 5 == 0:\n",
    "        print(\n",
    "            f'Epoch [{epoch + 1} / 100], Step[{i + 1} / {total_step}], Loss: {round(loss.item(), 4)}'\n",
    "            f'Accuracy : {accuracy}'\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "477689e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {0: {'step': tensor(100.),\n",
       "   'exp_avg': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 3.9140e-08,  7.2076e-07,  2.8947e-06, -4.7084e-07, -1.6364e-06,\n",
       "             1.2009e-06, -3.0252e-06, -1.2824e-06, -3.7163e-07, -1.4814e-06,\n",
       "             4.7092e-06, -2.6926e-06,  5.6231e-07, -8.5042e-07, -1.1989e-06,\n",
       "             2.6796e-06],\n",
       "           [ 3.4043e-07, -5.1706e-07,  9.3601e-07,  6.9616e-07, -5.0328e-07,\n",
       "            -6.0139e-07, -7.6896e-07, -7.8893e-07,  6.5484e-07,  6.8622e-07,\n",
       "             4.8278e-07, -4.9727e-07,  3.9291e-08,  8.2765e-07, -8.1476e-07,\n",
       "            -7.0617e-07],\n",
       "           [ 3.6480e-07, -2.8316e-07,  7.1643e-07,  5.3605e-07, -7.7087e-07,\n",
       "            -3.9984e-07, -1.7791e-07, -4.0678e-07,  5.6478e-07,  1.2246e-07,\n",
       "             8.0193e-07, -1.7218e-07,  2.3558e-07,  1.9313e-07, -3.4247e-07,\n",
       "            -5.4822e-08],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 4.7797e-07, -5.0747e-07,  1.0298e-06,  6.1260e-07, -8.1553e-07,\n",
       "            -5.5893e-07, -4.4727e-07, -7.4620e-07,  7.4677e-07,  2.2210e-07,\n",
       "             8.6835e-07, -1.5754e-07,  1.0952e-07,  2.6404e-07, -6.6878e-07,\n",
       "            -3.6837e-07],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [-1.8223e-06,  1.9208e-06,  2.6384e-06, -2.6066e-06,  7.4112e-07,\n",
       "            -2.0085e-06, -1.6028e-06, -4.3523e-07, -9.8028e-07, -2.3380e-06,\n",
       "             2.5498e-06,  3.2715e-06,  1.6319e-06, -2.7073e-07, -2.8296e-06,\n",
       "            -5.0133e-07],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             0.0000e+00]]),\n",
       "   'exp_avg_sq': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [1.0023e-08, 3.1352e-08, 4.8164e-08, 1.5085e-08, 2.0828e-08, 2.7094e-08,\n",
       "            2.0690e-07, 7.4742e-09, 9.3074e-08, 1.4013e-07, 4.6314e-07, 1.7694e-07,\n",
       "            1.4433e-07, 3.6032e-08, 3.3918e-07, 4.3878e-07],\n",
       "           [1.0236e-07, 1.6077e-07, 5.2643e-08, 9.1617e-08, 4.1427e-08, 5.5628e-09,\n",
       "            1.4067e-07, 4.5665e-08, 1.0010e-07, 8.7398e-08, 1.0682e-08, 1.2805e-07,\n",
       "            1.9068e-08, 9.5128e-08, 2.1258e-07, 2.9408e-07],\n",
       "           [9.3532e-09, 7.5591e-09, 7.4802e-08, 1.4551e-07, 1.2661e-07, 3.3452e-08,\n",
       "            1.9398e-08, 9.1651e-09, 2.4019e-08, 7.9507e-10, 1.4724e-07, 1.2673e-08,\n",
       "            6.0453e-09, 1.0651e-07, 2.7825e-08, 2.7398e-09],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [1.4757e-08, 6.6230e-08, 1.0596e-07, 1.0106e-07, 5.3782e-08, 2.8236e-09,\n",
       "            7.0569e-08, 2.3533e-08, 5.0237e-08, 5.0971e-09, 3.7568e-08, 1.5997e-08,\n",
       "            2.8223e-08, 3.5870e-08, 1.1958e-07, 1.5625e-07],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [2.2004e-09, 1.0280e-08, 6.7808e-08, 4.9215e-08, 9.6657e-09, 2.5205e-08,\n",
       "            9.7333e-08, 5.1849e-09, 6.4205e-09, 1.1727e-07, 1.7489e-07, 3.9986e-08,\n",
       "            3.4703e-08, 6.7684e-09, 1.2037e-07, 2.3429e-07],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])},\n",
       "  1: {'step': tensor(100.),\n",
       "   'exp_avg': tensor([[ 3.2645e-07, -2.7416e-07,  4.2843e-07,  7.5758e-07, -5.4792e-07,\n",
       "            -9.5601e-07, -2.7279e-07, -8.6155e-07,  1.1217e-06,  6.1005e-07,\n",
       "             4.8725e-07, -3.3815e-07,  2.5273e-07,  5.3903e-07, -3.5948e-07,\n",
       "            -4.0924e-07],\n",
       "           [ 1.5817e-07, -5.6980e-08,  6.6296e-08,  1.0714e-07, -1.4580e-07,\n",
       "             4.1363e-07, -2.2939e-07, -1.0589e-07, -1.0157e-07, -2.8024e-07,\n",
       "             2.8296e-07, -2.2552e-07,  1.8578e-07,  9.0971e-07,  3.1660e-07,\n",
       "            -4.9164e-09],\n",
       "           [ 2.8628e-07, -1.9249e-07,  3.2376e-07,  5.2424e-07, -4.4124e-07,\n",
       "            -6.7095e-07, -3.0194e-07, -6.9632e-07,  8.5588e-07,  4.5180e-07,\n",
       "             4.0641e-07, -2.4815e-07,  1.3822e-07,  4.3367e-07, -3.2520e-07,\n",
       "            -3.0543e-07],\n",
       "           [ 1.4229e-06,  2.9328e-08,  1.0447e-06, -1.0545e-06, -1.8733e-06,\n",
       "             4.1714e-06, -3.0091e-06, -1.5398e-06, -1.0085e-06, -2.9684e-06,\n",
       "             3.6075e-06, -1.2099e-06,  1.9405e-06,  7.0671e-06,  1.5510e-06,\n",
       "             6.1280e-07],\n",
       "           [ 3.8378e-07, -1.2788e-07,  2.1616e-07,  4.3447e-07, -2.0232e-07,\n",
       "            -9.9256e-07, -1.1445e-06, -1.3023e-06,  1.2522e-06,  1.0763e-06,\n",
       "             4.1489e-07, -2.8947e-07, -4.4336e-07,  1.1880e-06, -1.0806e-06,\n",
       "            -6.1656e-07],\n",
       "           [-7.3831e-08, -1.5387e-07,  1.3130e-07,  4.1802e-07,  2.7752e-07,\n",
       "            -6.1981e-07, -4.6269e-07, -5.1557e-07,  4.4670e-07,  6.0774e-07,\n",
       "            -2.2481e-08, -3.9385e-07,  2.4637e-08,  1.6039e-06, -3.2307e-07,\n",
       "            -4.8446e-07],\n",
       "           [-2.4112e-06,  1.1021e-06,  1.9056e-06, -3.7131e-06,  9.3214e-07,\n",
       "            -2.7887e-06, -3.5354e-07, -4.0583e-07, -1.0258e-06, -4.2107e-07,\n",
       "             1.0546e-06,  1.2667e-06,  2.0832e-06, -8.2594e-07, -3.6732e-06,\n",
       "             3.7657e-08],\n",
       "           [ 1.7099e-06,  1.9269e-08,  1.3353e-06, -1.2608e-06, -2.3292e-06,\n",
       "             4.9861e-06, -3.6095e-06, -1.8975e-06, -1.1835e-06, -3.6159e-06,\n",
       "             4.4410e-06, -1.4795e-06,  2.4667e-06,  8.5794e-06,  1.8810e-06,\n",
       "             7.4064e-07],\n",
       "           [-2.1032e-06,  9.5995e-07,  1.6354e-06, -3.2143e-06,  8.3193e-07,\n",
       "            -2.4373e-06, -2.7861e-07, -3.2384e-07, -9.0139e-07, -3.5362e-07,\n",
       "             8.7547e-07,  1.1101e-06,  1.7775e-06, -7.8384e-07, -3.1908e-06,\n",
       "             2.9770e-08],\n",
       "           [-3.9812e-06,  1.9780e-06,  2.6651e-06, -6.5689e-06,  2.1420e-06,\n",
       "            -3.9791e-06, -1.3099e-06, -6.8321e-07, -2.0647e-06, -5.0889e-07,\n",
       "             1.3912e-06,  2.1254e-06,  2.6597e-06, -4.9687e-07, -6.2979e-06,\n",
       "             3.4877e-08],\n",
       "           [-4.8038e-07, -3.4515e-08, -4.6415e-07,  5.6572e-07,  6.7721e-07,\n",
       "            -1.8010e-06,  1.2533e-06,  5.8201e-07,  5.7694e-07,  1.3217e-06,\n",
       "            -1.5036e-06,  5.1351e-07, -9.3258e-07, -3.1897e-06, -6.7180e-07,\n",
       "            -2.7648e-07],\n",
       "           [-1.3679e-06,  6.5925e-07,  7.0811e-07, -2.1067e-06,  7.4131e-07,\n",
       "            -9.3719e-07,  7.0642e-08,  2.9240e-07, -1.0763e-06, -5.1582e-07,\n",
       "             2.1419e-07,  7.8353e-07,  9.0093e-07, -7.5346e-07, -1.5478e-06,\n",
       "             2.0157e-07],\n",
       "           [-4.2368e-06,  1.9971e-06,  2.2728e-06, -6.6062e-06,  2.3350e-06,\n",
       "            -2.8184e-06,  3.5261e-08,  7.7460e-07, -3.2899e-06, -1.5649e-06,\n",
       "             7.8598e-07,  2.2970e-06,  2.9767e-06, -1.6831e-06, -4.8079e-06,\n",
       "             6.3257e-07],\n",
       "           [ 3.2474e-07, -2.6464e-07,  4.1700e-07,  7.3152e-07, -5.4025e-07,\n",
       "            -9.2578e-07, -2.7616e-07, -8.4523e-07,  1.0957e-06,  5.9323e-07,\n",
       "             4.8047e-07, -3.2599e-07,  2.3783e-07,  5.1599e-07, -3.5830e-07,\n",
       "            -3.9672e-07],\n",
       "           [ 7.4981e-07, -1.7827e-07,  5.2300e-07,  4.6690e-07, -1.3923e-06,\n",
       "            -3.8579e-07, -8.4864e-08, -8.1979e-07,  1.1488e-06,  6.2812e-09,\n",
       "             1.0511e-06,  3.9303e-09,  3.7452e-07, -1.0699e-06, -1.4949e-07,\n",
       "             8.0523e-08],\n",
       "           [ 5.2179e-07, -2.4165e-07,  4.5586e-07,  7.3320e-07, -6.8986e-07,\n",
       "            -1.0987e-06, -7.2907e-07, -1.2736e-06,  1.4714e-06,  8.6377e-07,\n",
       "             6.8723e-07, -3.3520e-07,  1.0041e-08,  6.6594e-07, -7.5957e-07,\n",
       "            -5.1409e-07],\n",
       "           [ 4.3594e-07, -2.3204e-07,  4.3103e-07,  6.1078e-07, -6.7772e-07,\n",
       "            -7.4837e-07, -4.6246e-07, -9.6039e-07,  1.1226e-06,  5.2110e-07,\n",
       "             6.4560e-07, -2.9299e-07,  2.0402e-07,  5.4075e-07, -4.0784e-07,\n",
       "            -3.3785e-07],\n",
       "           [-2.0497e-06,  1.1625e-06,  1.8422e-06, -3.9487e-06,  4.5669e-07,\n",
       "            -1.6340e-06, -4.0354e-07, -1.9820e-07, -1.4557e-06, -1.2479e-06,\n",
       "             1.4945e-06,  1.3100e-06,  2.2193e-06, -9.4105e-07, -3.0238e-06,\n",
       "             4.5806e-07],\n",
       "           [-2.6475e-06,  6.4540e-07, -3.5606e-07, -1.1106e-06,  2.5799e-06,\n",
       "            -4.7117e-06,  2.7262e-06,  1.7088e-06, -1.7184e-07,  2.2893e-06,\n",
       "            -3.2030e-06,  1.8664e-06, -1.0690e-06, -7.1008e-06, -2.9988e-06,\n",
       "            -4.0644e-07],\n",
       "           [ 1.4348e-06, -1.4531e-08,  1.1293e-06, -1.0331e-06, -1.8254e-06,\n",
       "             4.1927e-06, -3.3507e-06, -1.7934e-06, -9.5581e-07, -2.9001e-06,\n",
       "             3.7530e-06, -1.3838e-06,  2.0181e-06,  8.0095e-06,  1.4830e-06,\n",
       "             4.8137e-07],\n",
       "           [-1.8481e-07, -7.5848e-09, -4.8898e-07,  4.4541e-07,  5.3348e-07,\n",
       "            -7.3334e-07,  6.0344e-07,  4.4198e-07,  1.7289e-07,  7.2262e-07,\n",
       "            -1.0263e-06,  2.1691e-07, -8.4390e-07, -1.5549e-06, -2.0693e-07,\n",
       "            -1.9936e-07],\n",
       "           [-3.4798e-06,  1.6359e-06,  1.8203e-06, -5.3336e-06,  1.9465e-06,\n",
       "            -2.4133e-06,  9.9104e-08,  6.6775e-07, -2.6624e-06, -1.2106e-06,\n",
       "             5.5376e-07,  1.9024e-06,  2.3514e-06, -1.5647e-06, -3.9584e-06,\n",
       "             4.8396e-07],\n",
       "           [-1.2594e-06, -2.9129e-08, -1.1148e-06,  1.1520e-06,  1.6365e-06,\n",
       "            -3.9277e-06,  3.2453e-06,  1.7171e-06,  9.7473e-07,  2.7504e-06,\n",
       "            -3.5727e-06,  1.2826e-06, -1.9698e-06, -7.7171e-06, -1.2694e-06,\n",
       "            -4.5698e-07],\n",
       "           [ 5.2644e-07, -2.9322e-07,  5.2353e-07,  8.3783e-07, -8.2854e-07,\n",
       "            -1.1100e-06, -4.8784e-07, -1.1981e-06,  1.4866e-06,  7.6085e-07,\n",
       "             7.4245e-07, -3.3855e-07,  2.1698e-07,  4.4973e-07, -5.6358e-07,\n",
       "            -4.5144e-07],\n",
       "           [-2.4066e-07,  1.7058e-08, -2.8549e-07,  2.0692e-07,  3.4577e-07,\n",
       "            -7.3603e-07,  7.0417e-07,  4.2584e-07,  1.3735e-07,  5.2974e-07,\n",
       "            -7.9025e-07,  3.1087e-07, -4.9849e-07, -1.7994e-06, -2.4253e-07,\n",
       "            -5.7141e-08],\n",
       "           [-1.6638e-06,  1.0310e-09, -1.6744e-06,  1.6862e-06,  2.1685e-06,\n",
       "            -6.1822e-06,  4.7119e-06,  2.2851e-06,  1.9003e-06,  4.3963e-06,\n",
       "            -5.2427e-06,  2.1334e-06, -3.3067e-06, -1.2541e-05, -2.3648e-06,\n",
       "            -6.7810e-07],\n",
       "           [ 6.6389e-07, -1.7803e-07,  4.9262e-07,  4.3996e-07, -1.2555e-06,\n",
       "            -3.1998e-07, -5.6911e-08, -7.2137e-07,  1.0082e-06, -3.6716e-08,\n",
       "             9.6228e-07, -2.9256e-08,  4.0149e-07, -8.4910e-07, -7.5125e-08,\n",
       "             7.1659e-08],\n",
       "           [ 5.0856e-07, -9.8915e-08,  3.3199e-07,  2.6037e-07, -9.0684e-07,\n",
       "            -2.1253e-07, -1.3399e-07, -5.6253e-07,  7.4446e-07,  2.1716e-11,\n",
       "             7.0533e-07,  8.2911e-09,  1.9720e-07, -6.5562e-07, -1.4243e-07,\n",
       "             5.2353e-08],\n",
       "           [ 3.8776e-07, -1.7564e-07,  3.3680e-07,  4.9991e-07, -5.0671e-07,\n",
       "            -7.2584e-07, -5.7159e-07, -9.2887e-07,  1.0347e-06,  5.8585e-07,\n",
       "             5.2206e-07, -2.5450e-07,  1.5752e-08,  5.7753e-07, -5.3502e-07,\n",
       "            -3.6337e-07],\n",
       "           [ 2.5424e-09,  2.0555e-08, -2.0828e-08, -5.7623e-08,  6.1839e-09,\n",
       "             7.1750e-08, -9.1881e-09,  3.5757e-08, -5.5857e-08, -4.3211e-08,\n",
       "            -1.0674e-08,  2.6686e-08, -3.4817e-08, -6.2735e-08,  1.4214e-09,\n",
       "             2.9302e-08],\n",
       "           [ 1.1925e-06, -5.8410e-08,  9.5582e-07, -7.1376e-07, -1.4884e-06,\n",
       "             3.5072e-06, -2.7596e-06, -1.4656e-06, -8.1018e-07, -2.4418e-06,\n",
       "             3.1101e-06, -1.2676e-06,  1.7623e-06,  6.9919e-06,  1.3766e-06,\n",
       "             3.4839e-07],\n",
       "           [ 1.4721e-07, -1.1172e-07, -4.3613e-08,  3.5257e-07, -4.8769e-08,\n",
       "            -6.8548e-08, -1.1315e-07, -1.6115e-07,  2.3593e-07,  1.8688e-07,\n",
       "            -2.3867e-08, -1.6326e-07, -1.3533e-07,  3.7200e-07,  7.6369e-08,\n",
       "            -1.5363e-07]]),\n",
       "   'exp_avg_sq': tensor([[1.1864e-09, 5.6053e-08, 7.0849e-08, 4.2299e-07, 3.9401e-08, 5.6222e-07,\n",
       "            3.3108e-08, 1.3547e-07, 3.8415e-07, 1.6942e-07, 2.8360e-08, 7.9888e-08,\n",
       "            1.9040e-07, 3.1072e-07, 5.2432e-09, 8.1337e-08],\n",
       "           [1.0439e-08, 4.9227e-08, 2.1557e-07, 1.1462e-06, 1.6433e-07, 2.5735e-07,\n",
       "            6.2471e-07, 2.7276e-07, 2.2470e-08, 2.3330e-07, 8.7544e-07, 3.0099e-08,\n",
       "            3.3990e-07, 5.2445e-07, 2.4486e-07, 9.2498e-08],\n",
       "           [6.2531e-10, 5.5458e-09, 1.0449e-08, 3.1986e-08, 7.5534e-09, 3.4428e-08,\n",
       "            3.3341e-08, 3.1380e-08, 3.1852e-08, 7.7702e-09, 2.0064e-08, 1.6076e-08,\n",
       "            3.0785e-08, 3.1650e-07, 1.7242e-09, 6.7830e-09],\n",
       "           [1.1781e-07, 2.6318e-08, 9.2332e-08, 1.0556e-07, 2.4955e-07, 2.9618e-07,\n",
       "            1.1872e-07, 1.0575e-07, 5.4648e-08, 1.1502e-07, 3.4636e-07, 7.5111e-08,\n",
       "            3.2364e-07, 1.0932e-06, 2.0377e-07, 1.0584e-08],\n",
       "           [1.4719e-07, 1.9914e-08, 1.1902e-08, 3.4064e-07, 3.3023e-07, 1.4431e-06,\n",
       "            9.1778e-07, 1.2447e-06, 1.2013e-06, 1.4116e-06, 1.8063e-07, 1.7746e-07,\n",
       "            1.0726e-07, 3.3961e-06, 8.5373e-07, 5.1252e-07],\n",
       "           [2.4107e-08, 9.8137e-09, 2.9137e-09, 1.3883e-07, 1.3125e-07, 4.7739e-07,\n",
       "            8.6922e-08, 1.3853e-07, 1.5539e-07, 3.7698e-07, 3.0728e-08, 7.8575e-08,\n",
       "            6.0549e-09, 1.4071e-06, 9.5941e-08, 1.7576e-07],\n",
       "           [7.5538e-08, 1.3219e-08, 2.7353e-07, 3.0816e-07, 8.4520e-08, 2.1646e-07,\n",
       "            1.2154e-07, 2.5165e-07, 6.9021e-08, 6.5279e-09, 4.3520e-07, 2.6811e-08,\n",
       "            4.7596e-07, 4.8856e-07, 3.4458e-07, 2.6011e-09],\n",
       "           [4.6479e-08, 2.8014e-09, 1.8370e-07, 1.9103e-07, 1.1248e-07, 1.7661e-07,\n",
       "            1.0392e-07, 5.0565e-08, 2.3098e-08, 2.1203e-07, 4.0524e-07, 2.1965e-08,\n",
       "            5.8047e-07, 7.5744e-07, 4.1487e-08, 2.9466e-08],\n",
       "           [6.1444e-08, 1.0237e-08, 1.5342e-07, 2.0189e-07, 3.8009e-08, 1.9615e-07,\n",
       "            5.0560e-08, 1.1677e-07, 3.8371e-08, 4.4925e-09, 2.0134e-07, 2.1515e-08,\n",
       "            2.5086e-07, 2.3234e-07, 2.5496e-07, 1.4780e-09],\n",
       "           [5.2355e-07, 2.2750e-07, 1.1687e-06, 4.1588e-06, 1.6610e-07, 7.2865e-07,\n",
       "            3.9082e-06, 2.5175e-06, 1.9534e-07, 4.3207e-08, 2.6907e-06, 1.8288e-07,\n",
       "            1.4264e-06, 9.8799e-06, 4.2138e-06, 1.3427e-08],\n",
       "           [2.8203e-09, 9.1321e-10, 7.8892e-09, 2.1309e-08, 3.4738e-09, 1.4325e-08,\n",
       "            3.1701e-08, 1.7319e-08, 1.3280e-09, 7.0055e-09, 2.8799e-08, 1.9139e-09,\n",
       "            1.2910e-08, 1.0928e-07, 2.0093e-08, 2.9912e-10],\n",
       "           [1.5518e-07, 9.4774e-09, 3.1003e-08, 1.1644e-07, 1.6223e-07, 3.3770e-07,\n",
       "            1.4922e-08, 1.8452e-08, 1.3049e-08, 7.6384e-08, 3.2778e-09, 6.2464e-09,\n",
       "            4.7827e-08, 2.4740e-07, 2.6949e-07, 2.8888e-08],\n",
       "           [6.9906e-07, 1.6046e-07, 5.6752e-07, 3.5224e-06, 2.0186e-07, 6.1779e-07,\n",
       "            4.4395e-07, 9.6577e-08, 7.7054e-07, 7.6550e-07, 8.7816e-07, 1.4789e-07,\n",
       "            1.5787e-06, 2.4590e-06, 8.3222e-07, 1.6232e-07],\n",
       "           [1.0639e-09, 4.8141e-08, 6.1361e-08, 3.6272e-07, 3.5269e-08, 4.7866e-07,\n",
       "            2.9292e-08, 1.1519e-07, 3.2899e-07, 1.4277e-07, 2.4909e-08, 6.8095e-08,\n",
       "            1.6466e-07, 2.5962e-07, 4.7343e-09, 6.8711e-08],\n",
       "           [3.1162e-07, 5.9223e-08, 2.2316e-07, 3.2607e-07, 1.4400e-06, 1.6266e-07,\n",
       "            2.1151e-07, 3.8360e-07, 9.2048e-07, 4.1599e-09, 7.1431e-07, 9.7549e-09,\n",
       "            4.3281e-07, 1.0246e-06, 1.1144e-07, 1.4936e-08],\n",
       "           [7.4738e-08, 1.8956e-09, 1.4849e-08, 8.0295e-08, 4.8366e-08, 5.7421e-07,\n",
       "            7.4651e-07, 9.8467e-07, 9.3027e-07, 7.3161e-07, 1.3613e-07, 2.5162e-08,\n",
       "            9.6665e-08, 7.4838e-07, 6.5963e-07, 1.7379e-07],\n",
       "           [1.0092e-07, 2.1732e-08, 1.0235e-07, 8.0663e-08, 3.2324e-07, 6.0662e-08,\n",
       "            1.7336e-07, 4.4763e-07, 3.8986e-07, 2.3347e-08, 4.5276e-07, 4.9572e-08,\n",
       "            1.6717e-07, 8.2685e-07, 5.9113e-09, 8.5081e-09],\n",
       "           [5.4704e-08, 1.5395e-08, 1.0112e-07, 2.4598e-07, 3.1988e-08, 1.3415e-07,\n",
       "            8.7565e-09, 1.5288e-08, 1.5690e-08, 1.3750e-08, 9.3093e-08, 4.6442e-08,\n",
       "            1.5272e-07, 3.0493e-07, 2.0501e-07, 1.4413e-08],\n",
       "           [4.5655e-08, 3.9061e-09, 2.9328e-08, 8.0605e-08, 3.4400e-08, 9.1242e-08,\n",
       "            8.3911e-08, 3.6207e-08, 1.1310e-08, 3.2905e-08, 8.3115e-08, 1.5785e-08,\n",
       "            7.7212e-08, 6.3674e-07, 6.5045e-08, 2.3804e-09],\n",
       "           [7.2774e-08, 7.6626e-09, 6.1940e-08, 2.0435e-07, 4.9034e-08, 1.3571e-07,\n",
       "            1.3740e-07, 4.7171e-08, 3.3927e-08, 7.5398e-08, 1.6037e-07, 1.9363e-08,\n",
       "            1.6420e-07, 9.5661e-07, 1.0284e-07, 5.0288e-09],\n",
       "           [1.0154e-07, 9.2173e-09, 1.3146e-06, 1.4048e-06, 1.1598e-06, 1.9728e-07,\n",
       "            3.0198e-07, 6.1008e-07, 8.9700e-08, 9.4174e-07, 2.9700e-06, 1.6255e-08,\n",
       "            3.5723e-06, 9.7874e-07, 7.4298e-08, 2.7820e-07],\n",
       "           [2.9865e-07, 6.0182e-08, 1.3670e-07, 1.0305e-06, 1.0601e-07, 1.9165e-07,\n",
       "            7.7826e-08, 3.0761e-08, 2.3030e-07, 1.4033e-07, 1.4753e-07, 7.4206e-08,\n",
       "            3.4492e-07, 4.7763e-07, 3.7871e-07, 3.5258e-08],\n",
       "           [1.4302e-08, 1.1249e-09, 3.3040e-08, 3.4106e-08, 6.4555e-08, 1.0091e-07,\n",
       "            7.1163e-08, 3.8739e-08, 9.5512e-09, 6.0044e-08, 1.5545e-07, 1.1485e-08,\n",
       "            8.6092e-08, 3.6763e-07, 1.8420e-08, 7.3478e-09],\n",
       "           [1.6629e-07, 6.0524e-08, 1.7960e-07, 5.7381e-07, 5.4914e-07, 1.0508e-06,\n",
       "            7.7194e-08, 1.0850e-06, 1.7817e-06, 5.2218e-07, 4.6877e-07, 5.9121e-08,\n",
       "            1.2540e-07, 1.5297e-07, 1.3854e-07, 1.1485e-07],\n",
       "           [8.3722e-09, 9.7359e-09, 3.2139e-08, 1.8740e-08, 4.1429e-09, 1.9222e-08,\n",
       "            3.0234e-07, 2.1033e-07, 3.5066e-08, 5.2706e-09, 1.4449e-07, 1.0036e-07,\n",
       "            1.0450e-07, 2.9450e-06, 9.5356e-09, 2.7387e-08],\n",
       "           [3.4751e-08, 1.7574e-09, 1.3029e-08, 1.3278e-08, 8.8398e-08, 6.3378e-08,\n",
       "            6.2129e-08, 5.0994e-08, 5.4541e-08, 3.1852e-08, 1.0116e-07, 9.8762e-09,\n",
       "            3.2151e-08, 2.9094e-07, 2.4578e-08, 1.9024e-09],\n",
       "           [1.6439e-07, 6.3734e-08, 1.9415e-07, 3.0977e-07, 8.9966e-07, 1.7314e-07,\n",
       "            3.3092e-07, 2.0416e-07, 4.3225e-07, 3.7451e-08, 5.5799e-07, 1.6020e-08,\n",
       "            5.4123e-07, 4.0035e-07, 1.6562e-07, 1.2418e-08],\n",
       "           [8.8389e-08, 4.9293e-09, 4.0771e-08, 4.0332e-08, 3.3144e-07, 5.8303e-08,\n",
       "            4.1137e-08, 1.2017e-07, 2.0134e-07, 8.3933e-09, 2.1014e-07, 1.0248e-09,\n",
       "            3.9671e-08, 2.8135e-07, 3.1559e-10, 5.7823e-09],\n",
       "           [4.1054e-08, 8.9787e-10, 1.5890e-08, 6.8709e-09, 3.8571e-08, 7.5336e-08,\n",
       "            3.6507e-07, 3.4852e-07, 2.0476e-07, 1.0369e-07, 1.6236e-07, 2.2250e-08,\n",
       "            3.1509e-08, 8.7451e-07, 1.2041e-07, 2.6822e-08],\n",
       "           [3.9442e-10, 2.1045e-08, 2.1355e-08, 1.6595e-07, 1.7928e-09, 2.6002e-07,\n",
       "            3.9912e-09, 6.4627e-08, 1.5643e-07, 9.5371e-08, 5.5039e-09, 3.5853e-08,\n",
       "            5.9927e-08, 2.0328e-07, 2.1279e-10, 4.3707e-08],\n",
       "           [1.7100e-07, 1.7131e-08, 1.3597e-07, 1.7828e-07, 4.3009e-07, 2.9022e-07,\n",
       "            1.4494e-07, 1.9543e-07, 1.0143e-07, 1.1231e-07, 5.6568e-07, 4.9925e-08,\n",
       "            2.6821e-07, 7.0295e-07, 1.7822e-07, 2.4126e-08],\n",
       "           [5.7339e-08, 1.0510e-07, 1.0118e-07, 1.0771e-06, 2.4529e-09, 9.8920e-08,\n",
       "            1.0834e-07, 6.1677e-08, 6.0847e-09, 2.5552e-09, 1.4654e-07, 1.8869e-07,\n",
       "            3.6180e-08, 5.4092e-07, 9.2430e-07, 4.1688e-08]])},\n",
       "  2: {'step': tensor(100.),\n",
       "   'exp_avg': tensor([-8.4749e-07,  3.8972e-07, -6.2277e-07,  2.9979e-06, -9.8848e-07,\n",
       "           -3.1557e-07, -2.2966e-06,  3.5747e-06, -1.9973e-06, -3.3200e-06,\n",
       "           -1.3380e-06, -6.9041e-07, -2.1164e-06, -8.2646e-07, -7.9521e-07,\n",
       "           -1.1135e-06, -7.8419e-07, -1.5264e-06, -3.3750e-06,  3.0568e-06,\n",
       "           -4.3785e-07, -1.7938e-06, -2.8592e-06, -1.1252e-06, -5.3921e-07,\n",
       "           -4.7744e-06, -6.6811e-07, -4.9997e-07, -7.4843e-07,  4.9141e-08,\n",
       "            2.6469e-06, -4.2777e-09]),\n",
       "   'exp_avg_sq': tensor([2.8178e-07, 7.4693e-09, 1.9352e-08, 1.4908e-07, 9.3193e-07, 1.5503e-07,\n",
       "           2.9464e-07, 9.0594e-08, 2.2961e-07, 1.1364e-06, 1.0333e-08, 1.5187e-07,\n",
       "           2.6317e-07, 2.4069e-07, 5.1466e-07, 6.7911e-07, 1.1672e-07, 1.9444e-07,\n",
       "           4.7674e-08, 6.9770e-08, 6.2286e-08, 1.0564e-07, 5.0072e-08, 1.2017e-06,\n",
       "           1.7935e-08, 5.8644e-08, 1.9604e-07, 1.1540e-07, 1.0145e-07, 1.2138e-07,\n",
       "           1.7021e-07, 3.4082e-07])},\n",
       "  3: {'step': tensor(100.),\n",
       "   'exp_avg': tensor([[-4.4615e-06, -1.5299e-05, -2.4783e-06, -2.2422e-05, -4.7184e-06,\n",
       "            -2.9310e-06, -1.4320e-05, -1.7968e-05, -1.7476e-05, -1.2659e-05,\n",
       "            -4.1685e-06, -3.2990e-06, -1.4538e-05, -4.8534e-06, -3.4179e-06,\n",
       "            -4.3572e-06, -6.3418e-06, -1.8946e-05, -1.5276e-05, -1.2748e-05,\n",
       "            -1.3921e-05, -1.7286e-05, -6.3019e-06, -6.7885e-06, -1.1710e-05,\n",
       "            -3.4873e-06, -3.1825e-06, -4.1366e-06, -3.7832e-06, -6.3487e-08,\n",
       "            -2.3542e-05, -1.7881e-06],\n",
       "           [ 4.4615e-06,  1.5299e-05,  2.4783e-06,  2.2422e-05,  4.7184e-06,\n",
       "             2.9310e-06,  1.4320e-05,  1.7968e-05,  1.7476e-05,  1.2659e-05,\n",
       "             4.1685e-06,  3.2990e-06,  1.4538e-05,  4.8534e-06,  3.4179e-06,\n",
       "             4.3572e-06,  6.3418e-06,  1.8946e-05,  1.5276e-05,  1.2748e-05,\n",
       "             1.3921e-05,  1.7286e-05,  6.3019e-06,  6.7885e-06,  1.1710e-05,\n",
       "             3.4873e-06,  3.1825e-06,  4.1366e-06,  3.7832e-06,  6.3487e-08,\n",
       "             2.3542e-05,  1.7881e-06]]),\n",
       "   'exp_avg_sq': tensor([[1.4760e-05, 2.6242e-06, 6.1157e-07, 7.9858e-06, 1.7398e-05, 4.2133e-06,\n",
       "            2.2468e-05, 9.3610e-06, 9.9499e-05, 7.9413e-06, 1.1551e-06, 9.8001e-06,\n",
       "            8.0547e-06, 1.7966e-05, 7.9468e-06, 4.5422e-06, 2.5889e-05, 5.2932e-05,\n",
       "            6.7671e-06, 3.4948e-06, 4.6052e-06, 1.2683e-05, 2.6074e-06, 4.1140e-05,\n",
       "            2.5889e-06, 5.5196e-06, 8.0956e-06, 1.3038e-05, 6.0454e-06, 2.6874e-07,\n",
       "            8.4009e-06, 1.9743e-05],\n",
       "           [1.4760e-05, 2.6242e-06, 6.1157e-07, 7.9858e-06, 1.7398e-05, 4.2133e-06,\n",
       "            2.2468e-05, 9.3610e-06, 9.9499e-05, 7.9413e-06, 1.1551e-06, 9.8001e-06,\n",
       "            8.0547e-06, 1.7966e-05, 7.9468e-06, 4.5422e-06, 2.5889e-05, 5.2932e-05,\n",
       "            6.7671e-06, 3.4948e-06, 4.6052e-06, 1.2683e-05, 2.6074e-06, 4.1140e-05,\n",
       "            2.5889e-06, 5.5196e-06, 8.0956e-06, 1.3038e-05, 6.0454e-06, 2.6874e-07,\n",
       "            8.4009e-06, 1.9743e-05]])},\n",
       "  4: {'step': tensor(100.),\n",
       "   'exp_avg': tensor([-2.0178e-05,  2.0178e-05]),\n",
       "   'exp_avg_sq': tensor([3.8462e-05, 3.8462e-05])}},\n",
       " 'param_groups': [{'lr': 0.01,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'amsgrad': False,\n",
       "   'maximize': False,\n",
       "   'foreach': None,\n",
       "   'capturable': False,\n",
       "   'params': [0, 1, 2, 3, 4]}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b210588a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Your sentencehi\n",
      "hello\n",
      "Enter Your sentencetell me a joke\n",
      "see you later\n",
      "Enter Your sentenceJoke\n",
      "hi\n",
      "Enter Your sentencegreeting\n",
      "koskeshe kure khar savar\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     input_sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnter Your sentence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     token_input \u001b[38;5;241m=\u001b[39m tokenize_sent(input_sent, max_len, token2idx)\n\u001b[0;32m      6\u001b[0m     input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(token_input)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mlen\u001b[39m(token_input), \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1174\u001b[0m     )\n\u001b[1;32m-> 1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1216\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "while True:\n",
    "    input_sent = input('Enter Your sentence')\n",
    "    token_input = tokenize_sent(input_sent, max_len, token2idx)\n",
    "    input_tensor = torch.tensor(token_input).view(len(token_input), 1)\n",
    "    \n",
    "    output = model(input_tensor)\n",
    "    \n",
    "    label = torch.argmax(output)\n",
    "    tag = label2tag[int(label)]\n",
    "    \n",
    "    for item in data:\n",
    "        if item['tag'] == tag:\n",
    "            break\n",
    "            \n",
    "    print(random.choice(item['responses']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf3902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e99ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
